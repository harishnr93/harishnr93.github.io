<!DOCTYPE HTML>
<!--
	Harish by HTML5 UP
	html5up.net | @harishnr
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Harish - Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Portfolio</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About</a></li>
							<li><a href="experience.html">Experience</a></li>
							<li><a href="education.html">Education</a></li>
							<li class="active"><a href="projects.html">Theses and Projects</a></li>
							<li><a href="skills.html">Skills</a></li>
							
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/harish-natarajan-ravi-325337b1/" class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/harishnr93" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="docs/harish-natarajan-ravi-cv-en.pdf" class="fa fa-download"><span class="label" style="margin-left: 5px;">Resume</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Theses</h1>
								</header>
								
								<!--<div class="image main"><img src="images/porsche.jpg" alt="" /></div>-->
								<div class="image main">
									<img src="images/masterthesis_parking.jpg" alt="" class="centered-image">
								</div>
								<h3> Generation and Relocalization of Parking Maps </h3>
								<h4 style="margin-top: -15px;"> C++, ROS2 | Porsche Engineering GmbH | Mönsheim, DE</h4>
								<li> Designed and implemented a parking map pipeline using SLAM algorithms.</li>
								<li> Reconstructed and Relocalized vehicle within the generated parking map.  </li>
								<li> Evaluated the real-time performance of the pipeline in vehicle and simulation. </li>
								<li> Enhanced the performance of parking assist systems. </li>

								<!--<div class="image main"><img src="images/pic01.jpg" alt="" /></div>-->
								<div class="image main">
									<img src="images/speechsignals.jpg" alt="" class="centered-image">
								</div>
								<h3> Design, Simulation and Implementation of an optimal Adaptive Filter </h3>
								<h4 style="margin-top: -15px;"> MATLAB, Verilog | Visvesvaraya Technological University | Bengaluru, IN</h4>
								<!--<li> Designed and implemented of optimal adaptive filter.</li>>-->
								<li> Designed and Developed Adaptive Filtering techniques for Speech Signals in Noisy Environments</li>
								<li> Implemented Adaptive Algorithms on Xilinx Spartan 6 FPGA.</li>
								<li> Optimized FPGA Designs for Resource Efficiency and Low Power.</li>
								<li> Solved Varying Background Noise in Speech Signals.</li>
								<!-- Designed and implemeted algo. using MAtlab and Verilog-->

								<header class="major">
									<h1 style="margin-top: 150px;">Projects</h1>
								</header>

								<!--<div class="image main"><img src="images/getlab.jpg" alt="" /></div>-->
								<div class="image main">
									<img src="images/getlab.jpg" alt="" class="centered-image2">
								</div>
								<h3> Disaster Response Robots | C++, ROS1</h3>
								<h4 style="margin-top: -15px;"> Grundlagen der Elektrotechnik Lab | Paderborn, DE</h4>
								<p> The use of autonomous robots in times of natural disasters can be of great help. The robot must be capable of performing multiple actions - behavioral control, object recognition and handling, exploration, and mapping. </p>
								<p> The mapping system plays a vital role in improving the localization issue. As part of the project, we had to reconstruct the LOAM pipeline using SLAM concepts, where I had to extend the implementation of Loop Closure using a LiDAR scanner and camera data to fix the localization problem with the help of various 2D and 3D Key point extraction and descriptor algorithms using cross-platform library functions such as OpenCV.</p>

								
								<div class="image main">
									<img src="images/autonomous_vehicle_perception.jpg" alt="" class="centered-image">
								</div>
								<h3> Autonomous Vehicle Perception | Python, Computer Vision</h3>
								<h4 style="margin-top: -15px;"> Independent Development Projects | Leonberg, DE</h4>
								<p> Developed a perception pipeline for self-driving cars using Python, leveraging OpenCV, NumPy, and custom perception algorithms. The system processes a pre-recorded dataset containing RGB images, depth maps, semantic segmentation, and object detection data. It performs key perception tasks such as drivable space estimation using RANSAC, lane line detection, and object detection with distance estimation. The pipeline integrates multiple vision-based techniques to enhance environmental awareness, enabling the identification of drivable areas and obstacles. This project demonstrates a comprehensive approach to autonomous vehicle perception, crucial for safe navigation.</p>
								
								<div class="image main">
									<img src="images/visual_Odom.jpg" alt="" class="centered-image">
								</div>
								<h3> Visual Odometry for Camera Motion Estimation | Python, Pose Estimation</h3>
								<h4 style="margin-top: -15px;"> Independent Development Projects | Leonberg, DE</h4>
								<p> Implemented a visual odometry pipeline using feature extraction and matching techniques to estimate camera motion from sequential images. The system utilizes ORB features, FLANN matching, and Essential Matrix Decomposition (or PnP with RANSAC) to track movement and reconstruct the camera trajectory. The project integrates dataset handling, feature visualization, and trajectory estimation for real-time motion analysis. Outputs include matched feature visualizations and 3D camera trajectory plots. This implementation serves as a foundation for further enhancements, such as advanced feature descriptors, bundle adjustment, and loop closure detection for improved accuracy.</p>
								
								<div class="image main">
									<img src="images/radar_perception.jpg" alt="" class="centered-image">
								</div>
								<h3> Automotive Radar Perception Pipeline | ROS2, CAN, Object Tracking</h3>
								<h4 style="margin-top: -15px;"> Independent Development Projects | Leonberg, DE</h4>
								<p>Implemented a modular radar perception pipeline based on the Conti ARS408 radar sensor within the ROS 2 framework. The project centered around a ROS 2 lifecycle node that subscribed to real-time CAN bus messages, decoded raw radar frames, and generated dynamic object tracks with rich metadata including position, velocity, orientation, and object classification. Lifecycle states were leveraged for deterministic startup, shutdown, and fault handling, ensuring system reliability. The node published object lists, TF transforms, and visualization markers in RViz, enabling seamless integration into autonomous systems. Core components included low-level bitfield parsing, temporal object state management, and 3D visualization of ego-vehicle and target objects. The implementation demonstrates advanced skills in real-time sensor fusion, middleware architecture, and embedded robotics perception.</p>
								
								<div class="image main">
									<img src="images/depth_estimation_transformers.jpg" alt="" class="centered-image">
								</div>
								<h3> Monocular Depth Estimation with Transformers | Python, Computer Vision </h3>
								<h4 style="margin-top: -15px;"> Independent Development Projects | Leonberg, DE</h4>
								<p>Developed an interactive depth estimation pipeline using the transformers library and the Depth-Anything V2 model. 
									The system supports image input from both local files and web URLs and generates predicted depth maps using a state-of-the-art transformer-based architecture. 
									Leveraged Hugging Face’s pipeline abstraction for model loading and inference, with GPU acceleration when available. The application includes robust user input handling, image preprocessing, and result visualization using Matplotlib. This project demonstrates core skills in applying deep learning models to visual perception tasks, with potential applications in augmented reality, robotics, and autonomous systems—where depth estimation is critical for navigation, object interaction, and spatial understanding.</p>
								
								<div class="image main">
									<img src="images/object_detection_media.gif" alt="" class="centered-image">
								</div>
								<h3> YOLO Models and Real-Time Detection Transformer | DNN, Object Detection</h3>
								<h4 style="margin-top: -15px;"> Independent Development Projects | Leonberg, DE</h4>
								<p>Performed a comprehensive evaluation of modern object detection architectures, including YOLOv8, YOLOv10, YOLO11, YOLO12, and RT-DETRv2, to analyze their suitability across a range of deployment scenarios. The project explored a spectrum of design approaches—from lightweight, CNN-based models to advanced transformer-integrated frameworks—each optimized for varying trade-offs between speed, accuracy, and hardware efficiency. Key innovations examined included open-vocabulary detection, box-free training, and end-to-end DETR-style pipelines. Developed and optimized custom benchmarking tools using PyTorch, TorchVision, and CUDA to measure real-time performance across representative datasets. Findings offer practical guidance for selecting detection models in robotics, autonomous driving, healthcare imaging, and retail analytics. This project demonstrates advanced proficiency in applied deep learning, model benchmarking, and real-time computer vision systems.</p>
								<div class="image main">
									<img src="images/img_classification_cnn.jpg" alt="" class="centered-image">
								</div>
								<h3> Deep Learning-Based Image Classification with CNN | Deep Learning, PyTorch</h3>
								<h4 style="margin-top: -15px;"> Independent Development Projects | Leonberg, DE</h4>
								<p> Developed a deep learning pipeline for image classification using a Convolutional Neural Network (CNN) in PyTorch. The system automatically downloads and preprocesses datasets from Kaggle, applies transformations, and utilizes a custom dataset loader. The CNN model consists of convolutional layers with ReLU activation and max pooling, trained with cross-entropy loss and Adam optimizer. The project tracks training progress, evaluates model accuracy on test data, and supports inference on new images. Future enhancements include data augmentation, transfer learning with pre-trained models, and hyperparameter tuning for improved performance.</p>
								
								<!--<div class="image main"><img src="images/pic01.jpg" alt="" /></div>-->
								<div class="image main">
									<img src="images/dtmf.jpg" alt="" class="centered-image">
								</div>
								<h3> Design and Implementation of a DTMF based home automation system </h3>
								<h4 style="margin-top: -15px;"> Embedded C/C++ | Visvesvaraya Technological University | Bengaluru, IN</h4>
								<p> Controlling your home appliance from anywhere is most desirable if you are a person occupied with a lot of day to day tasks at your work place. In this project I designed a home automation system that can be controlled from any of your mobile phones using a technology used since the beginning of telephones - DTMF tones. </p>
							
								<!--<div class="image main"><img src="images/pic01.jpg" alt="" /></div>-->
								<div class="image main">
									<img src="images/linefollower.jpg" alt="" class="centered-image">
								</div>
								<h3> Line Follower Robot Using AVR Microcontroller Development Board </h3>
								<h4 style="margin-top: -15px;"> Embedded C/C++ | Visvesvaraya Technological University | Bengaluru, IN</h4>
								<p> Line follower is an Autonomous Robot which follows either black line in white or white line in black area. Robot must be able to detect particular line and keep following it. Line-following robots are very popular for its accurate line detection algorithms with analog outputs of reflective optical sensors and also home-made encoders, which help record all information about the racing track. </p>

							</section>

					</div>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Harish Natarajan Ravi</li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>